{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38db2f82-5999-4ccc-8146-d61ce5c71a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global imports\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "from delta import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a074586c-7e12-408c-b042-76239e8e8a91",
   "metadata": {},
   "source": [
    "## Funções para facilitar os exemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f48e91-0afd-4c34-bb3f-e10db1317fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spark_session():\n",
    "    \"\"\"\n",
    "    Create and configure a SparkSession with Delta Lake support.\n",
    "    \n",
    "    This function initializes a local Spark session with Delta Lake extensions enabled,\n",
    "    which allows working with Delta tables. The session is configured to use all\n",
    "    available cores on the local machine.\n",
    "\n",
    "    The configuration includes:\n",
    "    - Delta Lake SQL extensions\n",
    "    - Delta Lake catalog implementation\n",
    "    - Automatic handling of Delta Lake dependencies via Maven\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pyspark.sql.SparkSession\n",
    "        A configured SparkSession object with Delta Lake support enabled.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> spark = get_spark_session()\n",
    "    >>> df = spark.range(10)  # Create a test DataFrame\n",
    "    >>> df.show()\n",
    "    \n",
    "    Notes:\n",
    "    ------\n",
    "    - Requires PySpark and delta-spark packages to be installed\n",
    "    - Uses local mode with all available cores ('local[*]')\n",
    "    - The session should be stopped using spark.stop() when no longer needed\n",
    "    \"\"\"\n",
    "    builder = (\n",
    "        pyspark.sql.SparkSession.builder.master(\"local[*]\")\n",
    "            .config(\n",
    "                \"spark.sql.extensions\", \n",
    "                \"io.delta.sql.DeltaSparkSessionExtension\"\n",
    "            )\n",
    "            .config(\n",
    "                \"spark.sql.catalog.spark_catalog\", \n",
    "                \"org.apache.spark.sql.delta.catalog.DeltaCatalog\"\n",
    "            )\n",
    "    )\n",
    "\n",
    "    spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca221883-9c09-46b4-affe-9c0c0953d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_products(spark, data=None, total_rows=2000, total_customers=20, total_years=5, start_year=2020):\n",
    "    \"\"\"\n",
    "    Generate a PySpark DataFrame with synthetic sales data.\n",
    "    \n",
    "    This function creates a realistic sales dataset with products, customers, and transaction details,\n",
    "    which can be used for testing, demonstrations, or data analysis exercises.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    spark : pyspark.sql.SparkSession\n",
    "        The active SparkSession instance required to create DataFrames.\n",
    "        \n",
    "    data : dict, optional\n",
    "        Dictionary containing custom data definitions with the following keys:\n",
    "        - 'products': Nested dictionary of product categories and items\n",
    "        - 'cities': List of cities\n",
    "        - 'payment_types': List of payment methods\n",
    "        If None (default), uses built-in sample data.\n",
    "        \n",
    "    total_rows : int, optional\n",
    "        Total number of sales records to generate (default: 2000).\n",
    "        \n",
    "    total_customers : int, optional\n",
    "        Number of distinct customers to generate (default: 20).\n",
    "        \n",
    "    total_years : int, optional\n",
    "        Number of years to spread the sales dates across (default: 5).\n",
    "        \n",
    "    start_year : int, optional\n",
    "        Base year for sales date generation (default: 2020).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pyspark.sql.DataFrame\n",
    "        A DataFrame with the following schema:\n",
    "        - id_sale: Integer (unique sale ID)\n",
    "        - customer: String (customer name)\n",
    "        - product: String (product name)\n",
    "        - category: String (product category)\n",
    "        - quantity: Integer (quantity sold)\n",
    "        - price: Double (unit price)\n",
    "        - date: Date (sale date)\n",
    "        - city: String (sale city)\n",
    "        - payment: String (payment method)\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> from pyspark.sql import SparkSession\n",
    "    >>> spark = SparkSession.builder.getOrCreate()\n",
    "    >>> sales_df = get_products(spark, total_rows=1000)\n",
    "    >>> sales_df.show(5)\n",
    "    \n",
    "    >>> custom_data = {\n",
    "    ...     \"products\": {\"Food\": [\"Apple\", \"Bread\"], \"Drinks\": [\"Water\"]},\n",
    "    ...     \"cities\": [\"New York\", \"Chicago\"],\n",
    "    ...     \"payment_types\": [\"Cash\", \"Credit\"]\n",
    "    ... }\n",
    "    >>> custom_sales = get_products(spark, data=custom_data)\n",
    "    \"\"\"\n",
    "    import random\n",
    "    from datetime import datetime, timedelta\n",
    "    import pyspark.sql.types as T\n",
    "    \n",
    "    # Initialize default data if none provided\n",
    "    if data is None:\n",
    "        products = {\n",
    "            \"Eletrônicos\": [\"Notebook\", \"Smartphone\", \"TV\", \"Fone de Ouvido\", \"Monitor\"],\n",
    "            \"Móveis\": [\"Mesa\", \"Cadeira\"],\n",
    "            \"Informática\": [\"Teclado\", \"Mouse\"]\n",
    "        }\n",
    "        cities = [\"São Paulo\", \"Rio de Janeiro\", \"Belo Horizonte\", \"Porto Alegre\", \n",
    "                 \"Curitiba\", \"Recife\", \"Salvador\", \"Fortaleza\"]\n",
    "        payment_types = [\"Cartão de Crédito\", \"Boleto\", \"PIX\", \"Cartão de Débito\"]\n",
    "    else:\n",
    "        products = data[\"products\"]\n",
    "        cities = data[\"cities\"]\n",
    "        payment_types = data[\"payment_types\"]\n",
    "\n",
    "    # Flatten product categories into item:category dictionary\n",
    "    products = {item: category for category, items in products.items() for item in items}\n",
    "\n",
    "    # Define DataFrame schema\n",
    "    schema = T.StructType([\n",
    "        T.StructField(\"id_sale\", T.IntegerType(), nullable=False),\n",
    "        T.StructField(\"customer\", T.StringType(), nullable=True),\n",
    "        T.StructField(\"product\", T.StringType(), nullable=True),\n",
    "        T.StructField(\"category\", T.StringType(), nullable=True),\n",
    "        T.StructField(\"qty\", T.IntegerType(), nullable=True),\n",
    "        T.StructField(\"price\", T.DoubleType(), nullable=True),\n",
    "        T.StructField(\"date\", T.DateType(), nullable=True),\n",
    "        T.StructField(\"city\", T.StringType(), nullable=True),\n",
    "        T.StructField(\"payment\", T.StringType(), nullable=True)\n",
    "    ])\n",
    "    \n",
    "    # Generate customer IDs\n",
    "    customers = [f\"customer_{i}\" for i in range(1, total_customers + 1)]  \n",
    "    \n",
    "    # Generate synthetic sales data\n",
    "    data = []\n",
    "    for i in range(1, total_rows + 1):\n",
    "        product = random.choice(list(products.keys()))\n",
    "        product_category = products[product]\n",
    "        price = round(random.uniform(100.0, 5000.0), 2)\n",
    "        qty = random.randint(1, 5)\n",
    "        days = total_years * 365\n",
    "        sale_date = datetime(start_year, 1, 1) + timedelta(days=random.randint(0, days))\n",
    "        customer = random.choice(customers)\n",
    "        city = random.choice(cities)\n",
    "        payment = random.choice(payment_types)\n",
    "        \n",
    "        data.append((\n",
    "            i, customer, product, product_category, qty, price, \n",
    "            sale_date.date(), city, payment\n",
    "        ))\n",
    "    \n",
    "    # Create and return Spark DataFrame\n",
    "    df_sales = spark.createDataFrame(data, schema=schema)\n",
    "    return df_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67c72f-2a69-4f0c-94b0-fa8a7b8b3a19",
   "metadata": {},
   "source": [
    "## ***Definições***\n",
    "\n",
    "O **Delta Lake** é uma camada de armazenamento que traz ACID, versionamento e otimizações para data lakes (ex: em cima do S3, HDFS ou Azure Data Lake). \n",
    "\n",
    "[Documentação oficial](https://docs.delta.io/latest/index.html)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Principais características\n",
    "1 - ***ACID Transactions***\n",
    "\n",
    "- Garantem que operações de leitura e escrita sejam atomicamente consistentes, mesmo em pipelines concorrentes.\n",
    "\n",
    "2 - ***Time Travel (Viagem no Tempo)***\n",
    "\n",
    "- Permite acessar versões anteriores dos dados usando timestamps ou version numbers.\n",
    "\n",
    "3 - ***Schema Enforcement & Evolution***\n",
    "\n",
    "- Valida o schema dos dados durante a escrita (evitando corrupção).\n",
    "\n",
    "- Permite evoluir o schema sem quebrar pipelines.\n",
    "\n",
    "4 - ***Upsert, Delete e Merge (Operações DML)***\n",
    "\n",
    "- Suporte a operações como MERGE INTO, DELETE e UPDATE, que não são nativas em Parquet/ORC.\n",
    "\n",
    "5 - ***Armazenamento Eficiente***\n",
    "\n",
    "- Usa Parquet como formato físico, com otimizações como:\n",
    "\n",
    "- Compactação (para reduzir custo de armazenamento).\n",
    "\n",
    "- Particionamento automático (para consultas mais rápidas).\n",
    "\n",
    "6 - ***Open Format***\n",
    "\n",
    " - Compatível com Spark, Pandas, Trino, Presto, Flink e outras ferramentas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f212c4-f234-48fb-aa41-1f0e0987e43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      ":: loading settings :: url = jar:file:/home/alberto/.cache/pypoetry/virtualenvs/pyspark-delta-Km3JpzXx-py3.13/lib/python3.13/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /home/alberto/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /home/alberto/.ivy2.5.2/jars\n",
      "io.delta#delta-spark_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-b18f890f-4074-45ce-83e0-a1c083770289;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.13;4.0.0 in central\n",
      "\tfound io.delta#delta-storage;4.0.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.13.1 in central\n",
      ":: resolution report :: resolve 171ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.13;4.0.0 from central in [default]\n",
      "\tio.delta#delta-storage;4.0.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.13.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-b18f890f-4074-45ce-83e0-a1c083770289\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/5ms)\n",
      "25/07/06 04:30:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+-----------+---+-------+----------+------------+-----------------+\n",
      "|id_sale|customer   |product       |category   |qty|price  |date      |city        |payment          |\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+------------+-----------------+\n",
      "|1      |customer_6 |Fone de Ouvido|Eletrônicos|2  |3347.86|2021-12-26|Curitiba    |Cartão de Débito |\n",
      "|2      |customer_20|Mesa          |Móveis     |3  |4463.29|2020-08-10|Porto Alegre|PIX              |\n",
      "|3      |customer_18|TV            |Eletrônicos|3  |4403.15|2021-11-03|Recife      |Boleto           |\n",
      "|4      |customer_9 |Mouse         |Informática|4  |2040.97|2022-12-10|São Paulo   |Cartão de Débito |\n",
      "|5      |customer_2 |Monitor       |Eletrônicos|5  |4213.25|2020-12-27|Porto Alegre|Cartão de Crédito|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a spark session with delta table\n",
    "spark = get_spark_session()\n",
    "\n",
    "df = get_products(spark, total_rows=5)\n",
    "\n",
    "\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f323e-4947-455d-b386-96801c2e44b0",
   "metadata": {},
   "source": [
    "## Leitura e escrita de uma delta table\n",
    "\n",
    "- A escrita podemos usar diretamente os métodos **write** passando **delta** como formato de arquivo\n",
    "- A leitura é feita através do método load, passando o **delta** como formato\n",
    "\n",
    "***Observação importante***\n",
    "\n",
    "Os dados são salvos com o formato **parquet** e isso pode induzir ao erro de fazer a sua leitura apenas com esse formato, o que pode **acarretar erros** na integridade dos dados, como as delta tables possuim a funcionalidade de time travel, os dados podem não ser deletados, mesmo utilizando a instrução delete o dado ainda permanece localmente (ainda é possível realmente apagar dados não utilizados com a funcão **vacuum** do delta table), suas alterações são registradas em transações dentro da pasta delta_log, e por isso a **leitura apenas do parquet sem os metadados** pode acarretar em valores incorretos.\n",
    "\n",
    "---\n",
    "\n",
    "### Estrutura de um diretório escrito com delta table\n",
    "\n",
    "![](./images/escrita_delta.png)\n",
    "\n",
    "- Gera uma tabela com metadados avançados, suporte a ACID e versionamento (armazenada como arquivos Parquet + log de transações).\n",
    "\n",
    "### Descrições dos arquivos\n",
    "| **Termo**         | **Descrição**                                                                  |\n",
    "| ----------------- | ------------------------------------------------------------------------------ |\n",
    "| **Parquet Files** | Arquivos de dados (armazenam os dados efetivos, otimizados para consultas).    |\n",
    "| **Delta Log**     | Pasta `_delta_log/` com registros de transações (arquivos JSON/Parquet).       |\n",
    "| **Checkpoint**    | Snapshot periódico do transaction log (em Parquet) para acelerar recuperações. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a6546c-b1fa-4c4f-8154-46984d51c9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/06 04:30:13 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# create a delta table\n",
    "# save on BRONZE/sales folder\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"./BRONZE/sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3217534-50ca-44ab-8a32-f9dcd553cd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+-----------+---+-------+----------+------------+-----------------+\n",
      "|id_sale|   customer|       product|   category|qty|  price|      date|        city|          payment|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+------------+-----------------+\n",
      "|      1| customer_6|Fone de Ouvido|Eletrônicos|  2|3347.86|2021-12-26|    Curitiba| Cartão de Débito|\n",
      "|      5| customer_2|       Monitor|Eletrônicos|  5|4213.25|2020-12-27|Porto Alegre|Cartão de Crédito|\n",
      "|      4| customer_9|         Mouse|Informática|  4|2040.97|2022-12-10|   São Paulo| Cartão de Débito|\n",
      "|      2|customer_20|          Mesa|     Móveis|  3|4463.29|2020-08-10|Porto Alegre|              PIX|\n",
      "|      3|customer_18|            TV|Eletrônicos|  3|4403.15|2021-11-03|      Recife|           Boleto|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read a delta table from path\n",
    "spark.read.format(\"delta\").load(\"./BRONZE/sales\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef9b75-7467-4f84-844e-2565cd6563b6",
   "metadata": {},
   "source": [
    "## `Classe DeltaTable`\n",
    "\n",
    "Além da leitura com o formato *delta*, podemos usar a classe `DeltaTable` para representar uma tabela Delta em memória.  \n",
    "Com ela podemos ter acessos a algumas funcionalidades que apenas a leitura como Dataframe não permite.\n",
    "\n",
    "---\n",
    "**Principais Funcionalidades**\n",
    "1. ***Operações de Modificação***\n",
    "- **MERGE**: Upsert (atualiza ou insere dados).\n",
    "- **UPDATE**: Modifica registros existentes.\n",
    "- **DELETE**: Remove registros.\n",
    "\n",
    "2. ***Controle de Versões***\n",
    "- **history()**: Mostra o histórico de alterações.\n",
    "- **timeTravel**: Acessa versões antigas.\n",
    "\n",
    "3. ***Otimizações***\n",
    "- **vacuum()**: Limpa versões não utilizadas.\n",
    "- **optimize()**: Compacta arquivos pequenos.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Principais Diferenças entre DeltaTable e DataFrame**\n",
    "\n",
    "| **Recurso**               | **`DeltaTable`**                          | **`DataFrame` (leitura delta)**          |\n",
    "|---------------------------|------------------------------------------|------------------------------------------|\n",
    "| **Operações DML**         | ✅ Suporta `MERGE`, `UPDATE`, `DELETE`   | ❌ Apenas leitura                        |\n",
    "| **Time Travel**           | ✅ Via `timeTravel` ou `history()`       | ✅ Via `.option(\"versionAsOf\", N)`       |\n",
    "| **Histórico de Versões**  | ✅ `delta_table.history()`               | ❌ Não mostra histórico diretamente       |\n",
    "| **Otimizações**           | ✅ `vacuum()`, `optimize()`              | ❌ Não aplicável                         |\n",
    "| **Esquema**              | ✅ Pode forçar evolução de esquema       | ❌ Só lê o esquema existente             |\n",
    "| **Uso em Queries SQL**    | ❌ Não pode ser usado em `spark.sql()`   | ✅ Pode ser registrado como tabela SQL    |\n",
    "\n",
    "---\n",
    "\n",
    "- Ambos usam o **mesmo formato físico** (arquivos Parquet + log de transações Delta).\n",
    "- `DeltaTable` é uma **camada superior** que expõe operações de modificação.\n",
    "- `DataFrame` é uma **visão imutável** dos dados, mas é mais flexível para consultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46701ff4-7e00-43bc-a0b0-4af021be0bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'delta.tables.DeltaTable'>\n"
     ]
    }
   ],
   "source": [
    "# create from path\n",
    "delta_table = DeltaTable.forPath(spark, \"./BRONZE/sales\")\n",
    "\n",
    "print(type(delta_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a96c3a30-80f5-47fb-98de-368171a009a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+-----------+---+-------+----------+------------+-----------------+\n",
      "|id_sale|   customer|       product|   category|qty|  price|      date|        city|          payment|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+------------+-----------------+\n",
      "|      1| customer_6|Fone de Ouvido|Eletrônicos|  2|3347.86|2021-12-26|    Curitiba| Cartão de Débito|\n",
      "|      5| customer_2|       Monitor|Eletrônicos|  5|4213.25|2020-12-27|Porto Alegre|Cartão de Crédito|\n",
      "|      4| customer_9|         Mouse|Informática|  4|2040.97|2022-12-10|   São Paulo| Cartão de Débito|\n",
      "|      2|customer_20|          Mesa|     Móveis|  3|4463.29|2020-08-10|Porto Alegre|              PIX|\n",
      "|      3|customer_18|            TV|Eletrônicos|  3|4403.15|2021-11-03|      Recife|           Boleto|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "delta_table.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178874c1-c48b-469e-ab7e-d78b121c2b67",
   "metadata": {},
   "source": [
    "## Upset(update + insert)/Merge\n",
    "\n",
    "Podemos atualizar os dados com a delta table usando uma chave de refência para os registros e os métodos:\n",
    "- **whenMatchedUpdadeAll()** - Atualiza a linha onde acontecer o match das chaves\n",
    "- **whenNotMatchedInsertAll()** - Insere os registros que não deram match entre as chaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4b72c79-5735-4845-b931-d7f12ddac7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+-----------+---+-------+----------+------------+-----------------+\n",
      "|id_sale|   customer|       product|   category|qty|  price|      date|        city|          payment|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+------------+-----------------+\n",
      "|      1| customer_6|Fone de Ouvido|Eletrônicos|  2|3347.86|2021-12-26|    Curitiba| Cartão de Débito|\n",
      "|      5| customer_2|       Monitor|Eletrônicos|  5|4213.25|2020-12-27|Porto Alegre|Cartão de Crédito|\n",
      "|      4| customer_9|         Mouse|Informática|  4|2040.97|2022-12-10|   São Paulo| Cartão de Débito|\n",
      "|      2|customer_20|          Mesa|     Móveis|  3|4463.29|2020-08-10|Porto Alegre|              PIX|\n",
      "|      3|customer_18|            TV|Eletrônicos|  3|4403.15|2021-11-03|      Recife|           Boleto|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# current version\n",
    "delta_table = DeltaTable.forPath(spark, \"./BRONZE/sales\")\n",
    "delta_table.toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ef4ba1b-d267-4ec8-9b7b-0c8b966566d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "|id_sale|   customer|       product|   category|qty|  price|      date|          city|         payment|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "|      1| customer_1|      Notebook|Eletrônicos|  1|4381.02|2021-08-20|     São Paulo|             PIX|\n",
      "|      2| customer_9|    Smartphone|Eletrônicos|  4|2311.84|2021-02-03|Belo Horizonte|Cartão de Débito|\n",
      "|      3| customer_9|       Cadeira|     Móveis|  3|3774.18|2023-04-12|        Recife|Cartão de Débito|\n",
      "|      4|customer_16|Fone de Ouvido|Eletrônicos|  3|1448.87|2023-09-03|Belo Horizonte|          Boleto|\n",
      "|      5| customer_6|          Mesa|     Móveis|  1| 753.71|2020-05-03|        Recife|Cartão de Débito|\n",
      "|      6|customer_13|       Teclado|Informática|  4|3564.91|2021-06-09|     São Paulo|Cartão de Débito|\n",
      "|      7|customer_18|      Notebook|Eletrônicos|  5|3524.76|2021-04-26|      Salvador|             PIX|\n",
      "|      8|customer_14|       Cadeira|     Móveis|  4|4391.35|2021-07-28|     Fortaleza|Cartão de Débito|\n",
      "|      9| customer_7|       Teclado|Informática|  5|4882.49|2020-09-05|        Recife|             PIX|\n",
      "|     10| customer_7|         Mouse|Informática|  3| 3880.5|2023-10-08|Rio de Janeiro|Cartão de Débito|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df = get_products(spark, total_rows=10)\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76abd903-745e-4006-ae74-6b31c714514b",
   "metadata": {},
   "source": [
    "Para o exemplo a seguir será usando apenas as vendas com ID`s maiores que 4 para que ocorra os seguintes processos com o Upsert:\n",
    "- A linha com ID 5 será atualizada, pois ele já existe na tabela\n",
    "- As linhas com 6 a 10, como não existem na ultima versão da tabela, serão inseridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d16eb2df-36f1-4c7a-9f04-f4326cef420e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------+-----------+---+-------+----------+--------------+----------------+\n",
      "|id_sale|   customer| product|   category|qty|  price|      date|          city|         payment|\n",
      "+-------+-----------+--------+-----------+---+-------+----------+--------------+----------------+\n",
      "|      5| customer_6|    Mesa|     Móveis|  1| 753.71|2020-05-03|        Recife|Cartão de Débito|\n",
      "|      6|customer_13| Teclado|Informática|  4|3564.91|2021-06-09|     São Paulo|Cartão de Débito|\n",
      "|      7|customer_18|Notebook|Eletrônicos|  5|3524.76|2021-04-26|      Salvador|             PIX|\n",
      "|      8|customer_14| Cadeira|     Móveis|  4|4391.35|2021-07-28|     Fortaleza|Cartão de Débito|\n",
      "|      9| customer_7| Teclado|Informática|  5|4882.49|2020-09-05|        Recife|             PIX|\n",
      "|     10| customer_7|   Mouse|Informática|  3| 3880.5|2023-10-08|Rio de Janeiro|Cartão de Débito|\n",
      "+-------+-----------+--------+-----------+---+-------+----------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df = new_df.filter(F.col(\"id_sale\") > 4)\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acd2e68e-cede-4c55-a864-9f6551c00ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/06 04:30:52 WARN MapPartitionsRDD: RDD 67 was locally checkpointed, its lineage has been truncated and cannot be recomputed after unpersisting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    delta_table.alias(\"old_data\")\n",
    "    .merge(\n",
    "        new_df.alias(\"new_data\"),\n",
    "        \"old_data.id_sale = new_data.id_sale\"\n",
    "    )\n",
    "    .whenMatchedUpdateAll() # update rows\n",
    "    .whenNotMatchedInsertAll() # insert new rows\n",
    "    .execute()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af3c7541-3f73-4efe-be00-6b485d880b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "|id_sale|   customer|       product|   category|qty|  price|      date|          city|         payment|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "|      5| customer_6|          Mesa|     Móveis|  1| 753.71|2020-05-03|        Recife|Cartão de Débito|\n",
      "|      6|customer_13|       Teclado|Informática|  4|3564.91|2021-06-09|     São Paulo|Cartão de Débito|\n",
      "|      7|customer_18|      Notebook|Eletrônicos|  5|3524.76|2021-04-26|      Salvador|             PIX|\n",
      "|      8|customer_14|       Cadeira|     Móveis|  4|4391.35|2021-07-28|     Fortaleza|Cartão de Débito|\n",
      "|      9| customer_7|       Teclado|Informática|  5|4882.49|2020-09-05|        Recife|             PIX|\n",
      "|     10| customer_7|         Mouse|Informática|  3| 3880.5|2023-10-08|Rio de Janeiro|Cartão de Débito|\n",
      "|      1| customer_6|Fone de Ouvido|Eletrônicos|  2|3347.86|2021-12-26|      Curitiba|Cartão de Débito|\n",
      "|      4| customer_9|         Mouse|Informática|  4|2040.97|2022-12-10|     São Paulo|Cartão de Débito|\n",
      "|      2|customer_20|          Mesa|     Móveis|  3|4463.29|2020-08-10|  Porto Alegre|             PIX|\n",
      "|      3|customer_18|            TV|Eletrônicos|  3|4403.15|2021-11-03|        Recife|          Boleto|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# new version \n",
    "spark.read.format(\"delta\").load(\"./BRONZE/sales\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe8d466-4407-4afa-9e64-15c8020b6688",
   "metadata": {},
   "source": [
    "## Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddfa3b50-3696-4161-8a9c-92d05faad392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/06 04:31:31 WARN DeleteCommand: Could not validate number of records due to missing statistics.\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    delta_table\n",
    "    .delete(\"payment =  'Boleto'\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8c812b0-14a7-46be-9064-d19f8ac1db6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "|id_sale|   customer|       product|   category|qty|  price|      date|          city|         payment|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "|      5| customer_6|          Mesa|     Móveis|  1| 753.71|2020-05-03|        Recife|Cartão de Débito|\n",
      "|      6|customer_13|       Teclado|Informática|  4|3564.91|2021-06-09|     São Paulo|Cartão de Débito|\n",
      "|      7|customer_18|      Notebook|Eletrônicos|  5|3524.76|2021-04-26|      Salvador|             PIX|\n",
      "|      8|customer_14|       Cadeira|     Móveis|  4|4391.35|2021-07-28|     Fortaleza|Cartão de Débito|\n",
      "|      9| customer_7|       Teclado|Informática|  5|4882.49|2020-09-05|        Recife|             PIX|\n",
      "|     10| customer_7|         Mouse|Informática|  3| 3880.5|2023-10-08|Rio de Janeiro|Cartão de Débito|\n",
      "|      1| customer_6|Fone de Ouvido|Eletrônicos|  2|3347.86|2021-12-26|      Curitiba|Cartão de Débito|\n",
      "|      4| customer_9|         Mouse|Informática|  4|2040.97|2022-12-10|     São Paulo|Cartão de Débito|\n",
      "|      2|customer_20|          Mesa|     Móveis|  3|4463.29|2020-08-10|  Porto Alegre|             PIX|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df from path\n",
    "spark.read.format(\"delta\").load(\"./BRONZE/sales\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd7912-17ed-43bb-962f-23c7e6d30797",
   "metadata": {},
   "source": [
    "## History e Time Travel\n",
    "\n",
    "Com o history podemos ver todas as alterações feitas na tabela e registradas nos metadados no delta_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "395f9671-3b09-4d27-ae12-2aba8600fe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "|version|           timestamp|userId|userName|operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n",
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "|      2|2025-07-06 04:31:...|  NULL|    NULL|   DELETE|{predicate -> [\"(...|NULL|    NULL|     NULL|          1|  Serializable|        false|{numRemovedFiles ...|        NULL|Apache-Spark/4.0....|\n",
      "|      1|2025-07-06 04:30:...|  NULL|    NULL|    MERGE|{predicate -> [\"(...|NULL|    NULL|     NULL|          0|  Serializable|        false|{numTargetRowsCop...|        NULL|Apache-Spark/4.0....|\n",
      "|      0|2025-07-06 04:30:...|  NULL|    NULL|    WRITE|{mode -> Overwrit...|NULL|    NULL|     NULL|       NULL|  Serializable|        false|{numFiles -> 6, n...|        NULL|Apache-Spark/4.0....|\n",
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    delta_table\n",
    "    .history()\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03850ac6-1db7-4f9b-afbe-29938ca3db28",
   "metadata": {},
   "source": [
    "## Time Travel\n",
    "\n",
    "- É possível voltar versões das tabelas usando o número da sua versão ou o seu timestamp\n",
    "- A leitura da tabela vai apontar para a ultima versão registrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "207dbe2c-9b14-44d5-bac5-b738f68bb0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+\n",
      "|version|timestamp              |\n",
      "+-------+-----------------------+\n",
      "|2      |2025-07-06 04:31:31.792|\n",
      "|1      |2025-07-06 04:30:51.647|\n",
      "|0      |2025-07-06 04:30:12.745|\n",
      "+-------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    delta_table\n",
    "        .history()\n",
    "        .select(\"version\", \"timestamp\")\n",
    "        .show(truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af0ca9d6-b2a5-416d-bd9f-55a39712931b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "|id_sale|   customer|       product|   category|qty|  price|      date|          city|         payment|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "|      5| customer_6|          Mesa|     Móveis|  1| 753.71|2020-05-03|        Recife|Cartão de Débito|\n",
      "|      6|customer_13|       Teclado|Informática|  4|3564.91|2021-06-09|     São Paulo|Cartão de Débito|\n",
      "|      7|customer_18|      Notebook|Eletrônicos|  5|3524.76|2021-04-26|      Salvador|             PIX|\n",
      "|      8|customer_14|       Cadeira|     Móveis|  4|4391.35|2021-07-28|     Fortaleza|Cartão de Débito|\n",
      "|      9| customer_7|       Teclado|Informática|  5|4882.49|2020-09-05|        Recife|             PIX|\n",
      "|     10| customer_7|         Mouse|Informática|  3| 3880.5|2023-10-08|Rio de Janeiro|Cartão de Débito|\n",
      "|      1| customer_6|Fone de Ouvido|Eletrônicos|  2|3347.86|2021-12-26|      Curitiba|Cartão de Débito|\n",
      "|      4| customer_9|         Mouse|Informática|  4|2040.97|2022-12-10|     São Paulo|Cartão de Débito|\n",
      "|      2|customer_20|          Mesa|     Móveis|  3|4463.29|2020-08-10|  Porto Alegre|             PIX|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# default - Current version\n",
    "spark.read.format(\"delta\").load(\"./BRONZE/sales\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "718d7f7a-7552-4a9c-a10d-79a475e917d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+-----------+---+-------+----------+------------+-----------------+\n",
      "|id_sale|   customer|       product|   category|qty|  price|      date|        city|          payment|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+------------+-----------------+\n",
      "|      1| customer_6|Fone de Ouvido|Eletrônicos|  2|3347.86|2021-12-26|    Curitiba| Cartão de Débito|\n",
      "|      5| customer_2|       Monitor|Eletrônicos|  5|4213.25|2020-12-27|Porto Alegre|Cartão de Crédito|\n",
      "|      4| customer_9|         Mouse|Informática|  4|2040.97|2022-12-10|   São Paulo| Cartão de Débito|\n",
      "|      2|customer_20|          Mesa|     Móveis|  3|4463.29|2020-08-10|Porto Alegre|              PIX|\n",
      "|      3|customer_18|            TV|Eletrônicos|  3|4403.15|2021-11-03|      Recife|           Boleto|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using date\n",
    "(\n",
    "    spark\n",
    "        .read.format(\"delta\")\n",
    "        .option(\"timestampAsOf\",\"2025-07-06 04:30:12.745\")\n",
    "        .load(\"./BRONZE/sales\")\n",
    "        .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef9c2745-fe3d-4dc3-8cd6-4170045b1685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "|id_sale|   customer|       product|   category|qty|  price|      date|          city|         payment|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "|      5| customer_6|          Mesa|     Móveis|  1| 753.71|2020-05-03|        Recife|Cartão de Débito|\n",
      "|      6|customer_13|       Teclado|Informática|  4|3564.91|2021-06-09|     São Paulo|Cartão de Débito|\n",
      "|      7|customer_18|      Notebook|Eletrônicos|  5|3524.76|2021-04-26|      Salvador|             PIX|\n",
      "|      8|customer_14|       Cadeira|     Móveis|  4|4391.35|2021-07-28|     Fortaleza|Cartão de Débito|\n",
      "|      9| customer_7|       Teclado|Informática|  5|4882.49|2020-09-05|        Recife|             PIX|\n",
      "|     10| customer_7|         Mouse|Informática|  3| 3880.5|2023-10-08|Rio de Janeiro|Cartão de Débito|\n",
      "|      1| customer_6|Fone de Ouvido|Eletrônicos|  2|3347.86|2021-12-26|      Curitiba|Cartão de Débito|\n",
      "|      4| customer_9|         Mouse|Informática|  4|2040.97|2022-12-10|     São Paulo|Cartão de Débito|\n",
      "|      2|customer_20|          Mesa|     Móveis|  3|4463.29|2020-08-10|  Porto Alegre|             PIX|\n",
      "|      3|customer_18|            TV|Eletrônicos|  3|4403.15|2021-11-03|        Recife|          Boleto|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using version\n",
    "(\n",
    "    spark\n",
    "        .read.format(\"delta\")\n",
    "        .option(\"versionAsOf\",1)\n",
    "        .load(\"./BRONZE/sales\")\n",
    "        .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3884d4dc-078d-4112-87d3-7ed6f577311e",
   "metadata": {},
   "source": [
    "## Restore\n",
    "\n",
    "As visões anteriores apenas exibiram os dados da tabela ao longo do tempo, mas caso seja necessário retornar a tebela para uma versão anterior o delta table também tem esse tipo de funcionalidades\n",
    "- restoreToVersion - Restaura a tabela a partir de uma versão\n",
    "- restoreToTimestamp - Restaura a tabela a partir de uma data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c220df84-257b-414a-bf45-1a18c9249125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "|id_sale|   customer|       product|   category|qty|  price|      date|          city|         payment|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "|      5| customer_6|          Mesa|     Móveis|  1| 753.71|2020-05-03|        Recife|Cartão de Débito|\n",
      "|      6|customer_13|       Teclado|Informática|  4|3564.91|2021-06-09|     São Paulo|Cartão de Débito|\n",
      "|      7|customer_18|      Notebook|Eletrônicos|  5|3524.76|2021-04-26|      Salvador|             PIX|\n",
      "|      8|customer_14|       Cadeira|     Móveis|  4|4391.35|2021-07-28|     Fortaleza|Cartão de Débito|\n",
      "|      9| customer_7|       Teclado|Informática|  5|4882.49|2020-09-05|        Recife|             PIX|\n",
      "|     10| customer_7|         Mouse|Informática|  3| 3880.5|2023-10-08|Rio de Janeiro|Cartão de Débito|\n",
      "|      1| customer_6|Fone de Ouvido|Eletrônicos|  2|3347.86|2021-12-26|      Curitiba|Cartão de Débito|\n",
      "|      4| customer_9|         Mouse|Informática|  4|2040.97|2022-12-10|     São Paulo|Cartão de Débito|\n",
      "|      2|customer_20|          Mesa|     Móveis|  3|4463.29|2020-08-10|  Porto Alegre|             PIX|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Current version\n",
    "spark.read.format(\"delta\").load(\"./BRONZE/sales\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ca7fbe8-9f87-4432-9fd3-b72be8175dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/06 04:32:47 WARN DAGScheduler: Broadcasting large task binary with size 1087.4 KiB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[table_size_after_restore: bigint, num_of_files_after_restore: bigint, num_removed_files: bigint, num_restored_files: bigint, removed_files_size: bigint, restored_files_size: bigint]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_table.restoreToVersion(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b1f4085-f54d-4186-a479-dfab1cdf598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "|id_sale|   customer|       product|   category|qty|  price|      date|          city|         payment|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "|      5| customer_6|          Mesa|     Móveis|  1| 753.71|2020-05-03|        Recife|Cartão de Débito|\n",
      "|      6|customer_13|       Teclado|Informática|  4|3564.91|2021-06-09|     São Paulo|Cartão de Débito|\n",
      "|      7|customer_18|      Notebook|Eletrônicos|  5|3524.76|2021-04-26|      Salvador|             PIX|\n",
      "|      8|customer_14|       Cadeira|     Móveis|  4|4391.35|2021-07-28|     Fortaleza|Cartão de Débito|\n",
      "|      9| customer_7|       Teclado|Informática|  5|4882.49|2020-09-05|        Recife|             PIX|\n",
      "|     10| customer_7|         Mouse|Informática|  3| 3880.5|2023-10-08|Rio de Janeiro|Cartão de Débito|\n",
      "|      1| customer_6|Fone de Ouvido|Eletrônicos|  2|3347.86|2021-12-26|      Curitiba|Cartão de Débito|\n",
      "|      4| customer_9|         Mouse|Informática|  4|2040.97|2022-12-10|     São Paulo|Cartão de Débito|\n",
      "|      2|customer_20|          Mesa|     Móveis|  3|4463.29|2020-08-10|  Porto Alegre|             PIX|\n",
      "|      3|customer_18|            TV|Eletrônicos|  3|4403.15|2021-11-03|        Recife|          Boleto|\n",
      "+-------+-----------+--------------+-----------+---+-------+----------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# current dataframe\n",
    "spark.read.format(\"delta\").load(\"./BRONZE/sales\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1a648f0-b2ed-4997-93b0-8ab3ba544105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "|version|           timestamp|userId|userName|operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n",
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "|      3|2025-07-06 04:32:...|  NULL|    NULL|  RESTORE|{version -> 1, ti...|NULL|    NULL|     NULL|          2|  Serializable|        false|{numRestoredFiles...|        NULL|Apache-Spark/4.0....|\n",
      "|      2|2025-07-06 04:31:...|  NULL|    NULL|   DELETE|{predicate -> [\"(...|NULL|    NULL|     NULL|          1|  Serializable|        false|{numRemovedFiles ...|        NULL|Apache-Spark/4.0....|\n",
      "|      1|2025-07-06 04:30:...|  NULL|    NULL|    MERGE|{predicate -> [\"(...|NULL|    NULL|     NULL|          0|  Serializable|        false|{numTargetRowsCop...|        NULL|Apache-Spark/4.0....|\n",
      "|      0|2025-07-06 04:30:...|  NULL|    NULL|    WRITE|{mode -> Overwrit...|NULL|    NULL|     NULL|       NULL|  Serializable|        false|{numFiles -> 6, n...|        NULL|Apache-Spark/4.0....|\n",
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# restore row added \n",
    "delta_table.history().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a1dd40-5cfb-4173-b4d3-36930c7307ec",
   "metadata": {},
   "source": [
    "## Vacuum\n",
    "\n",
    "- Remove arquivos de versões antigas que não são mais utilizadas\n",
    "- Limpa arquivos não referenciados (útil após operações de DELETE ou OVERWRITE)\n",
    "- Reduz o armazenamento utilizado\n",
    "- Default de 7 dias de retenção\n",
    "- Pode afetar o time travel\n",
    "\n",
    "```python\n",
    "# modo de uso\n",
    "delta_table.vacuum(24) # recebe horas como parâmetro\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2da0b4cc-60e2-4dfc-b3be-6df2990d7dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 0 files and directories in a total of 1 directories.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_table.vacuum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f972cc-5a6b-43b3-9f12-2293124bb9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
